{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Init"
      ],
      "metadata": {
        "id": "FVYDCatCk51o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zaIqKTzxAM0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfb02c5-9cdb-484e-bdc9-91a20e9ab64c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [1\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [W\u001b[0m\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [W\u001b[0m\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Ign:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,105 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,606 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,438 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,665 kB]\n",
            "Fetched 15.2 MB in 2s (6,835 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "52 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjHdzhIpxoc9",
        "outputId": "eca919b7-844a-4635-8b7d-6bce51bb77c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 72\n",
            "drwxr-xr-x 1 root root  4096 Nov  3 11:23 .\n",
            "drwxr-xr-x 1 root root  4096 Nov  3 11:17 ..\n",
            "-rw-r--r-- 1 root root 19173 Nov  3 11:23 attendance.parquet\n",
            "drwxr-xr-x 4 root root  4096 Oct 31 13:28 .config\n",
            "-rw-r--r-- 1 root root 32976 Nov  3 11:23 employee.parquet\n",
            "drwxr-xr-x 1 root root  4096 Oct 31 13:28 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавляем Hive таблицу employee\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "       .builder \\\n",
        "       .master('local[*]') \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .enableHiveSupport() \\\n",
        "       .getOrCreate()\n",
        "spark.read.parquet('employee.parquet').repartition(1).write.saveAsTable(\"employee\")\n",
        "spark.read.parquet('attendance.parquet').repartition(1).write.saveAsTable(\"attendance\")\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "NaOXEGaqI-6-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Старт сессии и импорт"
      ],
      "metadata": {
        "id": "urpm38BrlEBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируем необходимые библиотеки\n",
        "\n",
        "Документация PySpark: https://spark.apache.org/docs/latest/api/python/index.html\n",
        "\n",
        "Документация PySpark SQL Functions: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html"
      ],
      "metadata": {
        "id": "VbDr3R-IUhBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, SparkSession\n",
        "import pyspark.sql.functions as F"
      ],
      "metadata": {
        "id": "QFSDeF56I_C1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание спарк сессии\n",
        "spark = SparkSession \\\n",
        "       .builder \\\n",
        "       .master('local[*]') \\\n",
        "       .appName(\"Spark Practice\") \\\n",
        "       .enableHiveSupport() \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "UX6J_dbDBCBT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "798b41b9-6fc4-494d-b620-b823a9391b34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d846483e320>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - hive</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://da11729392ac:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark Practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#С какими файлами работаем?\n",
        "\n",
        "1) Будем работать с Hive-таблицами\n",
        "\n",
        "2) Данные о сотрудниках в компании"
      ],
      "metadata": {
        "id": "4YW5VV-HZx2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Смотрим, какие таблицы есть в Hive etastore\n",
        "spark.sql(\"show tables\").show()"
      ],
      "metadata": {
        "id": "XuQ8ZkDSpYWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d20439d7-808c-4092-9b12-a3974bf943d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+-----------+\n",
            "|namespace| tableName|isTemporary|\n",
            "+---------+----------+-----------+\n",
            "|  default|attendance|      false|\n",
            "|  default|  employee|      false|\n",
            "+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Есть 2 способа работать с данными в Spark\n",
        "# 1) Через Spark SQL: spark.sql(\" ... \").show()\n",
        "# 2) Через Spark DataFrame API: spark.read.table(\" ... \").show()"
      ],
      "metadata": {
        "id": "fh4P4MxyylWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Читаем таблицу employee и выводим ее схему\n",
        "spark.read.table(\"employee\").printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5XILFN5zD_l",
        "outputId": "0ec69fb5-8a94-4ae0-b04b-93687a09c3bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Id: integer (nullable = true)\n",
            " |-- LastName: string (nullable = true)\n",
            " |-- FirstName: string (nullable = true)\n",
            " |-- MiddleName: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Position: string (nullable = true)\n",
            " |-- Grade: string (nullable = true)\n",
            " |-- HireDate: date (nullable = true)\n",
            " |-- OfferAmount: double (nullable = true)\n",
            " |-- Education: string (nullable = true)\n",
            " |-- CurrentStatus: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Читаем таблицу attendance и выводим ее 5 первых строк\n",
        "spark.read.table(\"employee\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf-H6pS4zGyE",
        "outputId": "317b5264-dd0e-4342-c129-947a3b90aecb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+---------+------------+------+---+----------+--------------------+------+----------+-----------+-------------------+-------------+\n",
            "| Id|LastName|FirstName|  MiddleName|Gender|Age|Department|            Position| Grade|  HireDate|OfferAmount|          Education|CurrentStatus|\n",
            "+---+--------+---------+------------+------+---+----------+--------------------+------+----------+-----------+-------------------+-------------+\n",
            "|  1| Абрамов|   Самсон|Валерьянович|Female| 36| Analytics|     Аналитик данных|Стажер|2024-06-14|   89178.63|       Магистратура|       Уволен|\n",
            "|  2| Абрамов|   Анжела|   Тихонович|Female| 54|        IT|Продуктовый аналитик|Стажер|2015-12-20|  101972.96|       Магистратура|      Активен|\n",
            "|  3| Абрамов|Харлампий|   Елисеевич|Female| 38|        IT|  Разработчик систем|Стажер|2019-09-30|   88074.95|Среднее специальное|       Уволен|\n",
            "|  4| Абрамов|   Ерофей|Валентинович|  Male| 34| Analytics|Разработчик баз д...|Junior|2024-03-08|  120694.35|Среднее специальное|      Активен|\n",
            "|  5|  Авдеев|   Трофим|   Антонович|Female| 58|   Product|     Проект менеджер|Junior|2018-10-14|  121063.82|       Магистратура|       Уволен|\n",
            "+---+--------+---------+------------+------+---+----------+--------------------+------+----------+-----------+-------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HG_Yuif5zDiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Читаем таблицу attendance и выводим ее схему\n",
        "spark.read.table(\"attendance\").printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoPfE3GZyUVf",
        "outputId": "0419685d-674f-4f82-f5d5-189c5e77099b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Id: integer (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- WorkedHours: double (nullable = true)\n",
            " |-- AbsenceReason: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Читаем таблицу attendance и выводим ее 5 первых строк\n",
        "spark.read.table(\"attendance\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCJeb7r-yURG",
        "outputId": "1c23fcc2-ee9b-4bc1-d439-cb0d2b7082b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-----------+--------------+\n",
            "| Id|      Date|WorkedHours| AbsenceReason|\n",
            "+---+----------+-----------+--------------+\n",
            "|229|2024-05-30|        3.5|          NULL|\n",
            "|642|2024-09-12|       11.6|          NULL|\n",
            "|300|2024-04-30|        6.9|          NULL|\n",
            "|614|2024-03-04|        0.0|Personal Leave|\n",
            "|399|2024-02-06|        9.9|          NULL|\n",
            "+---+----------+-----------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qbLQUGZRyULg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывести среднюю, минимальную и максимальную зп у всех сотрудников (округлить до 2 знаков после запятой)\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "4cioqpg61O-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывести среднюю зп у Активных сотрудников в зависимости от Grade (округлить до 2 знаков после запятой)\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "H-TTUWrShrka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитать средний возраст всех сотрудников.\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "D4JBZYFKhrnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитать количество мужчин и женщин в компании.\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "wkbG7kDwhrp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитать количество сотрудников по отделам (Department).\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "7o7SHacdhrsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определить, как долго сотрудники работают в компании, используя разницу между текущей датой и датой их найма.\n",
        "# from pyspark.sql.functions import current_date, datediff\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "-xR-TVmwrITJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определить средний доход специалистов в зависимости от уровня образования\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "2-npJMGhrIQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитать среднюю продолжительность работы сотрудников в компании (с учетом даты найма).\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "0IL8opg6rIOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразовать CurrentStatus в Int (Уволен = 0, Активен = 1)\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "RVeeOTCCrIMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vdINQcl01sXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитать среднее количество отработанных часов для всех сотрудников.\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "yiNZVpQx1sNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитать среднее количество отработанных часов в зависимости от Грейда.\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "MJlVZKoJrIKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитать среднее количество отработанных часов в зависимости от Возраста.\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "v4-kLAy8rIHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитать среднее количество отработанных часов в зависимости от Пола сотрудника.\n",
        "spark.sql(\"\"\"\n",
        "\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "id": "gjzrnAeg2Koi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q6Cs24cA2KmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9NGUoX9O2TMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYgsShV22Kjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RyVzjD-X2KeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNyFSHux2KWG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}